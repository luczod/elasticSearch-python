{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f5e1cdf0",
            "metadata": {},
            "source": [
                "## Documentation\n",
                "\n",
                "To read more about how to apply pre-filtering with KNN search, visit the [docs](https://www.elastic.co/docs/reference/query-languages/query-dsl/query-dsl-knn-query#knn-query-filtering).\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e664ba3",
            "metadata": {},
            "source": [
                "## Connect to ElasticSearch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce1f96e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pprint import pprint\n",
                "from elasticsearch import Elasticsearch\n",
                "\n",
                "es = Elasticsearch(\"http://localhost:9200\")\n",
                "client_info = es.info()\n",
                "print(\"Connected to Elasticsearch!\")\n",
                "pprint(client_info.body)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "45f4b15f",
            "metadata": {},
            "source": [
                "## Preparing the index"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e4276a6",
            "metadata": {},
            "source": [
                "We are adding a new field with type `dense_vector` to store the embeddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b9e8732",
            "metadata": {},
            "outputs": [],
            "source": [
                "es.indices.delete(index=\"apod\", ignore_unavailable=True)\n",
                "es.indices.create(\n",
                "    index=\"apod\",\n",
                "    mappings={\n",
                "        \"properties\": {\n",
                "            \"embedding\": {\n",
                "                \"type\": \"dense_vector\",\n",
                "            }\n",
                "        }\n",
                "    },\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6f81cc0d",
            "metadata": {},
            "source": [
                "## Embedding model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc58a591",
            "metadata": {},
            "source": [
                "I chose the `all-MiniLM-L6-v2` model for its speed, compact size, and versatility as a general-purpose model. It features an embedding dimension of `384` and truncates text that exceeds `256` words. This model is very popular in the community with almost `50M` downloads in one month.\n",
                "\n",
                "To download and utilize this model, Hugging Face offers a Python package called `sentence-transformers`. This framework simplifies the process of computing dense vector representations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb72a6a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b0f988c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "331b669e",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = model.to(device)\n",
                "model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d6e09648",
            "metadata": {},
            "source": [
                "## Index documents"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4479a17",
            "metadata": {},
            "source": [
                "Let's use the `APOD` dataset in this notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "71049613",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "with open(\"../data/apod.json\") as f:\n",
                "    documents = json.load(f)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00477e0e",
            "metadata": {},
            "source": [
                "Let's use the embedding model to embed the `explanation` field of the `APOD` dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d96898d",
            "metadata": {},
            "source": [
                "Use the `bulk` API to index the documents in the `apod` index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ec400975",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "\n",
                "\n",
                "def get_embedding(text):\n",
                "    return model.encode(text)\n",
                "\n",
                "\n",
                "operations = []\n",
                "for document in tqdm(documents, total=len(documents), desc=\"Indexing documents\"):\n",
                "    year = document[\"date\"].split(\"-\")[0]\n",
                "    document[\"year\"] = int(year)\n",
                "\n",
                "    operations.append({\"index\": {\"_index\": \"apod\"}})\n",
                "    operations.append(\n",
                "        {\n",
                "            **document,\n",
                "            \"embedding\": get_embedding(document[\"explanation\"]),\n",
                "        }\n",
                "    )\n",
                "\n",
                "response = es.bulk(operations=operations)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e4d8e692",
            "metadata": {},
            "source": [
                "If the indexing is successful, you should see `response[\"errors\"]` as `False`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "69b1affd",
            "metadata": {},
            "outputs": [],
            "source": [
                "response[\"errors\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "193d0e09",
            "metadata": {},
            "source": [
                "## Pre-filtering with kNN Search"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "54651a36",
            "metadata": {},
            "source": [
                "### Regular kNN search"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc1ba37e",
            "metadata": {},
            "source": [
                "Regular kNN search means that we take the query, embed it, compute the similarity score between the query and every document in the index, and return the top k most similar documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9746c707",
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"What is a black hole?\"\n",
                "embedded_query = get_embedding(query)\n",
                "\n",
                "result = es.search(\n",
                "    index=\"apod\",\n",
                "    knn={\n",
                "        \"field\": \"embedding\",\n",
                "        \"query_vector\": embedded_query,\n",
                "        \"num_candidates\": 20,\n",
                "        \"k\": 10,\n",
                "    },\n",
                ")\n",
                "\n",
                "number_of_documents = result.body[\"hits\"][\"total\"][\"value\"]\n",
                "print(f\"Found {number_of_documents} documents\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc1bea4d",
            "metadata": {},
            "source": [
                "Here we got 10 documents that are most similar to the query \"What is a black hole?\". Let's print the first 3 documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "74186f65",
            "metadata": {},
            "outputs": [],
            "source": [
                "for hit in result.body[\"hits\"][\"hits\"][:3]:\n",
                "    print(f\"Score: {hit['_score']}\")\n",
                "    print(f\"Title: {hit['_source']['title']}\")\n",
                "    print(f\"Explanation: {hit['_source']['explanation']}\")\n",
                "    print(\"-\" * 80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6c3eccf",
            "metadata": {},
            "outputs": [],
            "source": [
                "for hit in result.body[\"hits\"][\"hits\"]:\n",
                "    print(f\"Year: {hit['_source']['year']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "61329303",
            "metadata": {},
            "source": [
                "Let's look at the years of the documents returned by the regular kNN search. We can see that the years are different, let's see how we can use pre-filtering to filter the documents based on the year."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5a95e7fd",
            "metadata": {},
            "source": [
                "### 2. Pre-filtering"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "58259730",
            "metadata": {},
            "source": [
                "Let's run the same query but this time we will use pre-filtering to filter the documents based on the year. Let's say we want to filter the documents to only include those from the year 2024.\n",
                "\n",
                "We do this by adding a `filter` clause to the kNN query. The `filter` clause is a regular query that filters the documents before the kNN search is performed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0469d744",
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"What is a black hole?\"\n",
                "embedded_query = get_embedding(query)\n",
                "\n",
                "result = es.search(\n",
                "    index=\"apod\",\n",
                "    knn={\n",
                "        \"field\": \"embedding\",\n",
                "        \"query_vector\": embedded_query,\n",
                "        \"num_candidates\": 20,\n",
                "        \"k\": 10,\n",
                "        \"filter\": {\"term\": {\"year\": 2024}},\n",
                "    },\n",
                ")\n",
                "\n",
                "number_of_documents = result.body[\"hits\"][\"total\"][\"value\"]\n",
                "print(f\"Found {number_of_documents} documents\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a68ed6b0",
            "metadata": {},
            "source": [
                "As you can see, the documents returned are only from the year 2024."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "078aafdc",
            "metadata": {},
            "outputs": [],
            "source": [
                "for hit in result.body[\"hits\"][\"hits\"]:\n",
                "    print(f\"Year: {hit['_source']['year']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f94e682",
            "metadata": {},
            "source": [
                "Let's look at the first 3 documents returned by the kNN search to confirm that they are similar to the query."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "898efe4e",
            "metadata": {},
            "outputs": [],
            "source": [
                "for hit in result.body[\"hits\"][\"hits\"][:3]:\n",
                "    print(f\"Score: {hit['_score']}\")\n",
                "    print(f\"Title: {hit['_source']['title']}\")\n",
                "    print(f\"Explanation: {hit['_source']['explanation']}\")\n",
                "    print(\"-\" * 80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
